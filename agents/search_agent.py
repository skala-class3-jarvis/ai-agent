from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_community.tools.tavily_search.tool import TavilySearchResults
from typing import Dict, List
import json, re
from dotenv import load_dotenv
from prompts.search_prompt import SEARCH_PROMPT_TEMPLATE

load_dotenv()

# Tavily ì´ˆê¸°í™”
tavily_tool = TavilySearchResults(k=5)  # ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ ìˆ˜ (í•„ìš” ì‹œ ëŠ˜ë¦¬ê¸°)
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (count ì¶”ê°€)
prompt = PromptTemplate(
    input_variables=["query", "results", "count"],
    template=SEARCH_PROMPT_TEMPLATE.strip()
)


# ---------------------------
# LangGraph ì²« ë…¸ë“œ (ìˆ˜ì •ë³¸)
# ---------------------------
async def startup_search_node(state: Dict) -> Dict:
    """LangGraph ì²« ë…¸ë“œ â€” ìŠ¤íƒ€íŠ¸ì—… íƒìƒ‰ (count ì ìš©, ë‹¤ë¥¸ ë…¸ë“œ ì˜í–¥ ì—†ìŒ)"""
    state["stage"] = "Startup Search"
    print(f"ì§„í–‰ ë‹¨ê³„: {state['stage']}")

    # ğŸ¯ ì´ ë…¸ë“œì—ì„œë§Œ ì‚¬ìš©í•  count
    count = state.get("count", 3)  # ê¸°ë³¸ 3ê°œ
    query = state.get("query", f"êµ­ë‚´ ì—ë“€í…Œí¬ ìŠ¤íƒ€íŠ¸ì—… {count}ê°œ")

    # Tavily ê²€ìƒ‰ ì‹¤í–‰
    search_results = tavily_tool.run(query)

    # count ì „ë‹¬ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    formatted_prompt = prompt.format(query=query, results=search_results, count=count)

    # LLM í˜¸ì¶œ
    response = await llm.ainvoke(formatted_prompt)
    text = response.content.strip()

    # JSON ë¸”ë¡ ì¶”ì¶œ
    match = re.search(r"\[.*\]", text, re.DOTALL)
    json_str = match.group(0) if match else text
    json_str = json_str.replace("```json", "").replace("```", "").strip()

    try:
        parsed = json.loads(json_str)
    except Exception:
        parsed = [{"raw_output": text}]

    # LLM ê²°ê³¼ê°€ listê°€ ì•„ë‹ ê²½ìš° ë³´ì •
    if not isinstance(parsed, list):
        parsed = [parsed]

    # âœ… ìŠ¤íƒ€íŠ¸ì—… ê°œìˆ˜ ê°•ì œ ì œí•œ
    startups = []
    for idx, item in enumerate(parsed[:count], start=1):
        if isinstance(item, dict):
            startups.append(item)
        else:
            startups.append({"name": f"startup-{idx}", "raw_output": item})

    print(f"íƒìƒ‰ ì™„ë£Œ â€” {len(startups)}ê°œ ìŠ¤íƒ€íŠ¸ì—… ë°œê²¬")

    current = startups[0] if startups else {}

    return {
        "startups": startups,
        "current_startup": current,
        "processed_startups": [],
        "done": False,
    }
